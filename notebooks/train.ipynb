{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Model training notebook for **EfficientSpeech: An On-Device Text to Speech Model**\n",
        "This goal of this notebook is to streamline training new models for EfficientSpeech.   \n",
        "  \n",
        "\n",
        "#### Links\n",
        "Official repository: https://github.com/roatienza/efficientspeech  \n",
        "Paper: https://ieeexplore.ieee.org/abstract/document/10094639\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwUFGOOaLcoH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNmrrM_ylkrW"
      },
      "source": [
        "Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z60gbCONlepj",
        "outputId": "606d6472-9a29-4c91-f488-37d6df88e800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration options\n",
        "Dataset parameters\n",
        "* dataset_name: the name of the dataset\n",
        "* dataset_location: folder path to dataset files\n",
        "* config_dir: location of configuration files\n",
        "* checkpoints_dir: location of checkpoint folder containing .ckpt files \n",
        "* output_dir: folder path to save all generated .ckpt files"
      ],
      "metadata": {
        "id": "liZc2svqHrM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IJwbFktvjXL",
        "outputId": "17a5ac89-64c5-48d4-ea5b-53a64840c8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/efficientspeech/config/dataset’: File exists\n"
          ]
        }
      ],
      "source": [
        "dataset_name = 'dataset' #@param {type:\"string\"}\n",
        "\n",
        "dataset_location = '/content/drive/MyDrive/dataset' #@param {type:\"string\"}\n",
        "\n",
        "config_dir = '/content/efficientspeech/config' #@param {type:\"string\"}\n",
        "\n",
        "checkpoints_dir = '/content/efficientspeech/checkpoints' #@param {type:\"string\"}\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/saved_checkpoints' #@param {type:\"string\"}\n",
        "\n",
        "dataset_config_dir = f'{config_dir}/{dataset_name}'\n",
        "!mkdir $dataset_config_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training options\n",
        "* accelerator: One of `cpu`, `gpu`, `tpu`, `cuda`, `auto`\n",
        "* devices: Per pytorch_lightning documentation - Will be mapped to either `gpus`, `tpu_cores`, `num_processes` or `ipus`, based on the accelerator type.\n",
        "* model_size_to_train: One of 'base', 'small', 'tiny'. Determines the command line options to start train.py with.\n",
        "* resume_from_checkpoint: If not None, ensure the .ckpt model type matches the model_size_to_train option\n",
        "* max_epochs: The officially published weights were trained to 5000 epochs "
      ],
      "metadata": {
        "id": "_xACIzkNHpTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accelerator is TPU for Colab\n",
        "accelerator = 'tpu' #@param {type:'string'} ['tpu', 'cuda', 'auto']\n",
        "\n",
        "# Devices\n",
        "devices = 1 #@param {type:'integer'}\n",
        "\n",
        "# Cmd line opts for training different size models \n",
        "model_size_to_train = \"base\" #@param [\"tiny\", \"small\", \"base\"]\n",
        "match (model_size_to_train):\n",
        "  case \"small\":\n",
        "    cmd_line_opts = '--n-blocks 3 --reduction 2'\n",
        "  case \"base\":\n",
        "    cmd_line_opts = '--head 2 --reduction 1 --expansion 2  --kernel-size 5 --n-blocks 3 --block-depth 3'\n",
        "  case _: #tiny\n",
        "    cmd_line_opts = ''\n",
        "\n",
        "# Path to a .ckpt checkpoint to resume from\n",
        "resume_from_checkpoint = \"/content/efficientspeech/checkpoints/base_eng_4M.ckpt\" #@param {type:'string'} \\ ['None','/content/efficientspeech/checkpoints/base_eng_4M.ckpt','/content/efficientspeech/checkpoints/small_eng_952k.ckpt','/content/efficientspeech/checkpoints/tiny_eng_266k.ckpt']\n",
        "if resume_from_checkpoint != \"None\":\n",
        "  cmd_line_opts += f' --resume-from-checkpoint {resume_from_checkpoint}'\n",
        "\n",
        "# Pretrained checkpoints stop at 5000\n",
        "max_epochs = 10000 #@param {type:\"integer\"}\n",
        "cmd_line_opts += f' --max_epochs {max_epochs}'\n",
        "\n",
        "\n",
        "!echo Command line arguments: $cmd_line_opts\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaaEDYQQ6xs3",
        "outputId": "7212a67b-46bd-4c37-a5d8-73e2c51827b2"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command line arguments: --head 2 --reduction 1 --expansion 2 --kernel-size 5 --n-blocks 3 --block-depth 3 --resume-from-checkpoint /content/efficientspeech/checkpoints/base_eng_4M.ckpt --max_epochs 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CSrbDeIloq3"
      },
      "source": [
        "# Setup dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haFIWkj6ls0p",
        "outputId": "9b87774f-fac6-4db1-a024-8e054653f1bf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'efficientspeech'...\n",
            "remote: Enumerating objects: 137, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 137 (delta 13), reused 9 (delta 3), pack-reused 99\u001b[K\n",
            "Receiving objects: 100% (137/137), 4.85 MiB | 14.83 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "/content/efficientspeech\n",
            "Branch 'training' set up to track remote branch 'training' from 'origin'.\n",
            "Switched to a new branch 'training'\n",
            "--2023-05-13 20:29:02--  https://github.com/roatienza/efficientspeech/releases/download/icassp2023/base_eng_4M.ckpt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/483135884/534649d3-be57-4dcd-88c4-fa0e9fbf0fd4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230513T202902Z&X-Amz-Expires=300&X-Amz-Signature=4198686174d99f3d715011640a8af8b1545ad89a419988baaa32b5e5f9e6dfe0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483135884&response-content-disposition=attachment%3B%20filename%3Dbase_eng_4M.ckpt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-13 20:29:02--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/483135884/534649d3-be57-4dcd-88c4-fa0e9fbf0fd4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230513T202902Z&X-Amz-Expires=300&X-Amz-Signature=4198686174d99f3d715011640a8af8b1545ad89a419988baaa32b5e5f9e6dfe0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483135884&response-content-disposition=attachment%3B%20filename%3Dbase_eng_4M.ckpt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51373179 (49M) [application/octet-stream]\n",
            "Saving to: ‘/content/efficientspeech/checkpoints/base_eng_4M.ckpt’\n",
            "\n",
            "/content/efficients 100%[===================>]  48.99M  52.7MB/s    in 0.9s    \n",
            "\n",
            "2023-05-13 20:29:04 (52.7 MB/s) - ‘/content/efficientspeech/checkpoints/base_eng_4M.ckpt’ saved [51373179/51373179]\n",
            "\n",
            "--2023-05-13 20:29:04--  https://github.com/roatienza/efficientspeech/releases/download/icassp2023/small_eng_952k.ckpt\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/483135884/f07d8158-10ea-4530-86fa-aca33be2e9a8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230513T202904Z&X-Amz-Expires=300&X-Amz-Signature=17ba2579720eab98e977792e48997defae6fe3668b22c0c8ffd82cf202239670&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483135884&response-content-disposition=attachment%3B%20filename%3Dsmall_eng_952k.ckpt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-13 20:29:04--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/483135884/f07d8158-10ea-4530-86fa-aca33be2e9a8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230513T202904Z&X-Amz-Expires=300&X-Amz-Signature=17ba2579720eab98e977792e48997defae6fe3668b22c0c8ffd82cf202239670&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483135884&response-content-disposition=attachment%3B%20filename%3Dsmall_eng_952k.ckpt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15339531 (15M) [application/octet-stream]\n",
            "Saving to: ‘/content/efficientspeech/checkpoints/small_eng_952k.ckpt’\n",
            "\n",
            "/content/efficients 100%[===================>]  14.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-13 20:29:04 (118 MB/s) - ‘/content/efficientspeech/checkpoints/small_eng_952k.ckpt’ saved [15339531/15339531]\n",
            "\n",
            "--2023-05-13 20:29:04--  https://github.com/roatienza/efficientspeech/releases/download/icassp2023/tiny_eng_266k.ckpt\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/483135884/de523d8d-8fbd-4999-96e3-a6afff244ca0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230513T202905Z&X-Amz-Expires=300&X-Amz-Signature=2fcee1ee5e27482cbfd4d53940058e5fbf177c2a477a085adc67e637c94567e1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483135884&response-content-disposition=attachment%3B%20filename%3Dtiny_eng_266k.ckpt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-05-13 20:29:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/483135884/de523d8d-8fbd-4999-96e3-a6afff244ca0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230513%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230513T202905Z&X-Amz-Expires=300&X-Amz-Signature=2fcee1ee5e27482cbfd4d53940058e5fbf177c2a477a085adc67e637c94567e1&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=483135884&response-content-disposition=attachment%3B%20filename%3Dtiny_eng_266k.ckpt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7089915 (6.8M) [application/octet-stream]\n",
            "Saving to: ‘/content/efficientspeech/checkpoints/tiny_eng_266k.ckpt’\n",
            "\n",
            "/content/efficients 100%[===================>]   6.76M  30.7MB/s    in 0.2s    \n",
            "\n",
            "2023-05-13 20:29:05 (30.7 MB/s) - ‘/content/efficientspeech/checkpoints/tiny_eng_266k.ckpt’ saved [7089915/7089915]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.13 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.14 (from -r requirements.txt (line 2))\n",
            "  Downloading torchvision-0.14.0-cp310-cp310-manylinux1_x86_64.whl (24.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning===1.8.6 (from -r requirements.txt (line 3))\n",
            "  Downloading pytorch_lightning-1.8.6-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics==0.11 (from -r requirements.txt (line 4))\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-bolts==0.6 (from -r requirements.txt (line 5))\n",
            "  Downloading lightning_bolts-0.6.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.8/331.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unidecode (from -r requirements.txt (line 6))\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (6.0.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.10.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (8.4.0)\n",
            "Collecting einops (from -r requirements.txt (line 11))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting g2p-en (from -r requirements.txt (line 12))\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting validators (from -r requirements.txt (line 13))\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13->-r requirements.txt (line 1)) (4.5.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14->-r requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning===1.8.6->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning===1.8.6->-r requirements.txt (line 3)) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning===1.8.6->-r requirements.txt (line 3)) (2023.4.0)\n",
            "Collecting tensorboardX>=2.2 (from pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning===1.8.6->-r requirements.txt (line 3)) (23.1)\n",
            "Collecting lightning-utilities!=0.4.0,>=0.3.0 (from pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "  Downloading lightning_utilities-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13->-r requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->-r requirements.txt (line 7)) (1.10.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p-en->-r requirements.txt (line 12)) (3.8.1)\n",
            "Collecting distance>=0.1.3 (from g2p-en->-r requirements.txt (line 12))\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators->-r requirements.txt (line 13)) (4.4.2)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en->-r requirements.txt (line 12)) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p-en->-r requirements.txt (line 12)) (2022.10.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.2->pytorch-lightning===1.8.6->-r requirements.txt (line 3)) (3.20.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14->-r requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14->-r requirements.txt (line 2)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning===1.8.6->-r requirements.txt (line 3)) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning===1.8.6->-r requirements.txt (line 3))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: validators, distance\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=8a23e8b931a9ae389aa3d2eed57ab7852ceeb4814e8870ffb4b197a4ddd32313\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=cc64cdd7a4ad0189d7282c670f03f90df9d04180c8ac5ad08d5e6a6681185b5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "Successfully built validators distance\n",
            "Installing collected packages: distance, validators, unidecode, tensorboardX, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, multidict, lightning-utilities, frozenlist, einops, async-timeout, yarl, nvidia-cudnn-cu11, aiosignal, torch, g2p-en, aiohttp, torchvision, torchmetrics, pytorch-lightning, lightning-bolts\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.0 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 distance-0.1.3 einops-0.6.1 frozenlist-1.3.3 g2p-en-2.1.0 lightning-bolts-0.6.0 lightning-utilities-0.4.2 multidict-6.0.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pytorch-lightning-1.8.6 tensorboardX-2.6 torch-1.13.0 torchmetrics-0.11.0 torchvision-0.14.0 unidecode-1.3.6 validators-0.20.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "# Clone repository (Note: this is my fork with additional training options)\n",
        "!git clone https://github.com/v0xie/efficientspeech\n",
        "\n",
        "# Checkout training branch\n",
        "%cd /content/efficientspeech\n",
        "!git checkout training\n",
        "\n",
        "# Download model files\n",
        "!mkdir /content/efficientspeech/checkpoints\n",
        "!wget --show-progress --continue -O /content/efficientspeech/checkpoints/base_eng_4M.ckpt  https://github.com/roatienza/efficientspeech/releases/download/icassp2023/base_eng_4M.ckpt \n",
        "!wget --show-progress --continue -O /content/efficientspeech/checkpoints/small_eng_952k.ckpt  https://github.com/roatienza/efficientspeech/releases/download/icassp2023/small_eng_952k.ckpt\n",
        "!wget --show-progress --continue -O /content/efficientspeech/checkpoints/tiny_eng_266k.ckpt  https://github.com/roatienza/efficientspeech/releases/download/icassp2023/tiny_eng_266k.ckpt \n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbhGEtVAmM4f"
      },
      "source": [
        "Run inference to test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-ujPqMpmTIB"
      },
      "outputs": [],
      "source": [
        "!python demo.py --checkpoint https://github.com/roatienza/efficientspeech/releases/download/icassp2023/tiny_eng_266k.ckpt \\\n",
        "  --infer-device cpu --text \"the quick brown fox jumps over the lazy dog\" --wav-filename fox.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a new config (optional)"
      ],
      "metadata": {
        "id": "Gsf9fkRz393z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "uBTakj0RvjXO"
      },
      "outputs": [],
      "source": [
        "pp_config = f\"\"\"\n",
        "dataset: \"{dataset_name}\"\n",
        "\t\n",
        "path:\n",
        "  corpus_path: \"{dataset_location}/corpus\"\n",
        "  lexicon_path: \"/content/efficientspeech/lexicon/librispeech-lexicon.txt\"\n",
        "  raw_path: \"{dataset_location}/raw_data\"\n",
        "  preprocessed_path: \"{dataset_location}/preprocessed_data\"\n",
        "\n",
        "preprocessing:\n",
        "  val_size: 64\n",
        "  text:\n",
        "    text_cleaners: [\"english_cleaners\"]\n",
        "    language: \"en\"\n",
        "    max_length: 4096\n",
        "  audio:\n",
        "    sampling_rate: 22050\n",
        "    max_wav_value: 32768.0\n",
        "  stft:\n",
        "    filter_length: 1024\n",
        "    hop_length: 256\n",
        "    win_length: 1024\n",
        "  mel:\n",
        "    n_mel_channels: 80\n",
        "    mel_fmin: 0\n",
        "    mel_fmax: 8000 # please set to 8000 for HiFi-GAN vocoder, set to null for MelGAN vocoder\n",
        "  pitch:\n",
        "    feature: \"phoneme_level\" # support 'phoneme_level' or 'frame_level'\n",
        "    normalization: True\n",
        "  energy:\n",
        "    feature: \"phoneme_level\" # support 'phoneme_level' or 'frame_level'\n",
        "    normalization: True\n",
        "\"\"\"\n",
        "\n",
        "# Write config to file\n",
        "with open(f'{dataset_config_dir}/preprocess.yaml', mode='w') as f:\n",
        "  f.write(pp_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train a model \n",
        "### Run training"
      ],
      "metadata": {
        "id": "rq882mrs2E42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "%cd /content/efficientspeech/\n",
        "\n",
        "!python train.py $cmd_line_opts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-fMDTjFHF_O",
        "outputId": "9bc1732f-f2d5-441a-f980-5f2aa8555b9d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/efficientspeech\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/callbacks/data_monitor.py:20: UnderReviewWarning: The feature warn_missing_pkg is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  warn_missing_pkg(\"wandb\")\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:35: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:93: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/usr/local/lib/python3.10/dist-packages/pl_bolts/losses/self_supervised_learning.py:234: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/efficientspeech/train.py\", line 58, in <module>\n",
            "    pl_module = EfficientFSModule(preprocess_config=preprocess_config, lr=args.lr,\n",
            "  File \"/content/efficientspeech/model.py\", line 79, in __init__\n",
            "    self.hifigan = get_hifigan(checkpoint=hifigan_checkpoint,\n",
            "  File \"/content/efficientspeech/model.py\", line 32, in get_hifigan\n",
            "    ckpt = torch.load(checkpoint)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 795, in load\n",
            "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1012, in _legacy_load\n",
            "    result = unpickler.load()\n",
            "  File \"/usr/lib/python3.10/pickle.py\", line 1213, in load\n",
            "    dispatch[key[0]](self)\n",
            "  File \"/usr/lib/python3.10/pickle.py\", line 1254, in load_binpersid\n",
            "    self.append(self.persistent_load(pid))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 958, in persistent_load\n",
            "    wrap_storage=restore_location(obj, location),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 215, in default_restore_location\n",
            "    result = fn(storage, location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 182, in _cuda_deserialize\n",
            "    device = validate_cuda_device(location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 166, in validate_cuda_device\n",
            "    raise RuntimeError('Attempting to deserialize object on a CUDA '\n",
            "RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *IMPORTANT* - Copy all checkpoints to your drive"
      ],
      "metadata": {
        "id": "wbJYqQOhOexo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "source_dir = '/content/efficientspeech/lightning_logs'\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "   os.makedirs(output_dir)\n",
        "\n",
        "# Iterate through all subdirectories in the source directory\n",
        "for root, dirs, files in os.walk(source_dir):\n",
        "  for file in files:\n",
        "    # Check if the file is a checkpoint file\n",
        "    if file.endswith('.ckpt'):\n",
        "        source_file_path = os.path.join(root, file)\n",
        "        target_file_path = os.path.join(output_dir, file)\n",
        "\n",
        "      # Copy the file to the target directory if it doesn't exist\n",
        "    if not os.path.exists(target_file_path):\n",
        "        shutil.copy2(source_file_path, target_file_path)"
      ],
      "metadata": {
        "id": "4X6g9ONjOeKO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor training with Tensorboard"
      ],
      "metadata": {
        "id": "I8Tsfq7RJnLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext TensorBoard\n",
        "\n",
        "%tensorboard --logdir /content/efficientspeech/lightning_logs/"
      ],
      "metadata": {
        "id": "t5OCJGCsJpyq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}